NBER WORKING PAPER SERIES

HOW DEADLY IS COVID-19? UNDERSTANDING THE DIFFICULTIES WITH
ESTIMATION OF ITS FATALITY RATE
Andrew Atkeson
Working Paper 26965
http://www.nber.org/papers/w26965

NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
April 2020

The views expressed herein are those of the author and do not necessarily reflect the views of the
National Bureau of Economic Research.
NBER working papers are circulated for discussion and comment purposes. They have not been
peer-reviewed or been subject to the review by the NBER Board of Directors that accompanies
official NBER publications.
© 2020 by Andrew Atkeson. All rights reserved. Short sections of text, not to exceed two
paragraphs, may be quoted without explicit permission provided that full credit, including ©
notice, is given to the source.

How Deadly Is COVID-19? Understanding The Difficulties With Estimation Of Its Fatality
Rate
Andrew Atkeson
NBER Working Paper No. 26965
April 2020
JEL No. A1,C13
ABSTRACT
To understand how best to combat COVID-19, we must understand how deadly is the disease.
There is a substantial debate in the epidemiological lit- erature as to whether the fatality rate is
1% or 0.1%or somewhere in between. In this note, I use an SIR model to examine why it is
difficult to estimate the fatality rate from the disease and how long we might have to wait to
resolve this question absent a large-scale randomized testing program. I focus on un- certainty
over the joint distribution of the fatality rate and the initial number of active cases at the start of
the epidemic around January 15, 2020. I show how the model with a high initial number of active
cases and a low fatality rate gives the same predictions for the evolution of the number of deaths
in the early stages of the pandemic as the same model with a low initial number of active cases
and a high fatality rate. The problem of distinguishing these two parameterizations of the model
becomes more severe in the presence of effective mitigation measures. As discussed by many,
this uncertainty could be resolved now with large-scale randomized testing.

Andrew Atkeson
Bunche Hall 9381
Department of Economics
UCLA
Box 951477
Los Angeles, CA 90095-1477
and NBER
andy@atkeson.net

A Matlab Code for paper is available at
https://drive.google.com/drive/folders/1kaAFmnbhvnipDEYttDyK3sUvvxqZg21Y?usp=sharing

1

Introduction

There is a large debate in the epidemiology literature regarding the question of how
deadly is COVID-19.1 Is the fatality rate 1% or 0.1% or somewhere in between? If
we envision that 2/3 of all Americans will eventually get the disease absent sustained
mitigation measures, then this range of estimates in fatality rates results in a range
of cumulative deaths from 2.2 million at the high end and 220,000 at the low end.
What is the nature of this debate? Absent reliable data on the number of active
infections and/or the number of people who are now recovered from and resistant
to the disease, we are not able to directly compute the fatality rate from COVID-19
from observed deaths. That lack of data leaves us reliant on the use of models to
attempt to infer the fatality rate of the disease based on incomplete measurement.
Unfortunately, simple epidemiological models are not that helpful in this dimension
in the early phase of an epidemic. Absent accurate measurement of disease incidence,
one does not learn the true fatality rate until the deaths occur. That observation is
the focus on this note.
Specifically, I use a simple SIR model to examine why it is difficult to estimate
the fatality rate from the disease and how long we might have to wait to resolve this
question absent a large-scale randomized testing program. I focus on uncertainty
over the joint distribution of the fatality rate and the initial number of active cases
at the start of the epidemic around January 15, 2020. I show how the model with a
high initial number of active cases and a low fatality rate gives the same predictions
for the evolution of the number of deaths in the early stages of the pandemic as the
same model with a low initial number of active cases and a high fatality rate. I then
show that the problem of distinguishing these two parameterizations of the model
becomes more severe in the presence of effective mitigation measures.
1

See, for example this Op-Ed in the Wall Street Journal from March 24 https:
//www.wsj.com/articles/is-the-coronavirus-as-deadly-as-they-say-11585088464
or
this
news article in Science from March 25 https://www.sciencemag.org/news/2020/03/
mathematics-life-and-death-how-disease-models-shape-national-shutdowns-and-other

1

The points that I make here regarding the properties of simple SIR models are
essentially identical to those made by the epidemiological team at Oxford University
in Lourenco et al. (2020)2 and are closely related to those in Stock (2020). The
presentation of the argument here is intended simply as a pedagogical tool. The
model applied to Wuhan in Wang et al. (2020)3 is a useful framework for modeling the
uncertainties discussed here. Toda (2020)4 presents and regularly updates estimates
of a SIR model applied to the United States.5 . Chowell G (2007) is a useful discussion
of methods for estimating the transmission rate of an epidemic applied to the 1918-19
Spanish Flu.6 .
I make no effort to survey the literature on the measurements available of disease
incidence. This is a rapidly developing literature.7 Hopefully we will obtain sufficient
evidence to resolve the debate about the fatality rate of COVID-19 sooner than is
implied we might from this model.
In the remainder of this note, I present the model, lay out the measurement assumptions used, and then show model results.

2

The SIR Model

The population is set to N .
At each moment of time, the population is divided into three categories that sum
to the total of N . These are susceptible (no immunity) S, infected I, and resistant
2

available here https://www.medrxiv.org/content/10.1101/2020.03.24.20042291v1
available here https://www.medrxiv.org/content/10.1101/2020.03.03.20030593v1
4
available here https://arxiv.org/abs/2003.11221
5
see here for updated estimates https://sites.google.com/site/aatoda111/misc/covid19
6
available here https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2358966/
7
See
for
example
this
article
from
March
22
in
the
South
China
Morning
Post
https://www.scmp.com/news/china/society/article/
3076323/third-coronavirus-cases-may-be-silent-carriers-classified
or
this
commentary
by
Luigi
Zingales
from
March
17
https://promarket.org/
why-mass-testing-is-crucial-the-us-should-study-the-veneto-model-to-fight-covid-19/
3

2

(recovered or dead) R.
These fractions of the population evolve over time as follows
dS/dt = −βt

S
I
N

S
I − γI
N
dR/dt = γI

dI/dt = βt

βt = Rt γ
The parameter γ governs the rate at which agents who are infected become resistant (either recover or die) and hence stop transmitting the disease. The parameter
βt is the rate at which infected agents spread the virus to others that they encounter.
This parameter is a reduced form parameter that is impacted by the biological disease transmission mechanism, the rate at which agents bump into each other, and
the extent to which agents use prophylactics in their meetings. This parameter can
thus be impacted by mitigation measures such as social distancing and the use of
masks, etc.
The parameter Rt = βt /γ is the normalized transmission rate. This parameter
corresponds to the parameter cited in many news and academic studies. Note that
we can restate the equations of the model in terms of this parameter as
S
N


S
dI/dt = Rt − 1 γI
N
dS/dt = −Rt γ

dR/dt = γI

(1)

(2)
(3)

We denote the fatality rate from the disease by ν. That is, ν is the fraction of
agents who are resistant who are so because they died. Thus, cumulative deaths are

3

given by D = νR. The death rate per unit time is given by
dD/dt = νdR/dt
The initial conditions of the model are R = 0, I = I0 and S = N − I0 at date 0.
Note that in this model I abstract from the distinction between the time it takes to
stop being infections (γ) and the time it takes to die from the disease. As discussed in
the Oxford study, this distinction can be important for the quantitative implications
of the model.

2.1

Model Properties:

The following properties of the model are standard.
1. Model steady-states have I = 0. If I = 0, then any combination of S and R
that sum to N is a steady-state.
2. If I > 0, then dI/dt <= 0 if and only if Rt NS ≤ 1. Thus, the steady-states
reached from an initial value of I > 0 must have S/N ≤ 1/Rt .
3. The growth rate of the log of the number of active cases is given by
d log I
=
dt




S
Rt − 1 γ
N

(4)

4. The growth rate of the log of the total number of cases is given by
d log(I + R)
S I
= Rt γ
dt
N 1−S

(5)

5. Under the assumption of a constant mortality rate, the growth rate of the log
of the cumulative number of deaths is equal to the growth rate of the log of
4

the cumulative number of recovered cases and is given by
d log D
d log R
I
=
=γ
dt
dt
R

(6)

When Rt is constant, an analytical solution of the model is available.8

3

Measurement:

Assume that we have data on deaths D. That is, assume that we can measure both
the level and the growth rate of D. Note that this is a controversial assumption,9
but we make this assumption here to illustrate the problem of estimating ν in this
simple model in a stark manner.
Assume that we have a plausible range of estimates of γ, denoted by γ̃ ∈ [γmin , γmax ],
taken from clinical measurements of the progress of the disease. (Much of the uncertainty here is about how soon cases become infectious and whether there are unmeasured cases that have different properties of disease progression). In the illustrations
that I consider, I will set γ = 1/7.
Consider now measurement of the number of resistant individuals R. Clearly, if
we had accurate measures of the number of cases recovered R and the number of
deaths due to the disease D, it would be straightforward to estimate the fatality
rate ν = D/R. Hence, given accurate data on deaths, a large scale testing program
that would allow us to identify those who have had the disease and an accurate
count of those who died from the disease would allow for direct estimation of the
fatality rate ν. (See, for example, the plan in Germany to test 100,000 people at

8

See https://advanceseng.com/exact-analytical-solutions-susceptible-infected-recovered-sir-epidemic-model-sir-mod
See,
for
example
concerns
about
the
measurement
of
deaths
due
to
COVID-19
in
Italy
here
https://www.corriere.it/politica/20 marzo 26/
the-real-death-toll-for-covid-19-is-at-least-4-times-the-official-numbers-b5af0edc-6eeb-11ea-925b-a0c3cdbe1130.
shtml
9

5

random for antibodies to the disease.10 ) For the remainder of this note, I assume
that independent measures of R are not available. That is, I assume that measures
of R are derived by tracking confirmed active cases as these cases are resolved as is
done on this website.11
Consider next measurement of the number of active infections I. Note that if one
had accurate measures of the number of people actively infected, I, then one could
use data on the growth rate of the log of deaths and an estimate of the parameter
γ to infer the number of resistant individuals R using equation 6. I assume that an
accurate count of the number of actively infected individuals is not available. Instead, I assume that we have data on active infections up to a constant, proportional
measurement error. That is, assume that we observe I˜ = ηI I where the proportional
measurement error ηI is unknown. This assumption that we observe active cases
up to a constant, proportional, measurement error is likely an overstatement of the
data available as testing policies have been constantly changing. Again, we make
this assumption here to illustrate the problem of estimating ν in this simple model
in a stark manner.
Consider now the measurement of Rt . Under the assumption that we observe the
number of active infections up to proportional measurement error, we can measure
the growth of the log of infections but not the level of infections. Note then from
equation 4, we can estimate Rt in the earliest phase of the epidemic when we know
that S/N is close to 1 if we have an estimate of the parameter γ from clinical data.
For the purposes of the illustrations here, we assume that Rt in the earliest phase of
the epidemic without mitigation is equal to 2.5.
I now consider the difficulty of measuring the fatality rate ν in the early phase of
the epidemic given reasonable uncertainty over the initial condition I0 .
Assume that we have a plausible range of initial cases introduced into the United
10

https://www.dailymail.co.uk/news/article-8170903/Germany-100-000-people-coronavirus-antibody-tests.

html
11

See, for example, the statistics at https://www.worldometers.info/coronavirus/

6

States due to people returning from abroad with infections I˜0 ∈ [I0,min , I0,max ]. Start
the model on January 15. In the illustrations that I consider, I will set I0 equal to
either 330 active cases on January 15 or, alternatively 3300 active cases on January
15. This uncertainty would correspond to difficulties of measuring infections among
returning travelers and initial bursts of infection occurring in super-spreading events.
I now solve the model to demonstrate that the model’s implications for cumulative
deaths in the early phase of the epidemic are very similar under the assumption that
I0 = 330 and the fatality rate ν = 0.01 (1%) or the alternative assumption that
I0 = 3300 and the fatality rate ν = 0.001 (1/10 of 1%) despite the fact that these
two alternative parameter assumptions have an order of magnitude difference in their
implications for cumulative deaths over the long term.
I refer to the parameter combination of I0 = 330 and ν = 0.01 as the high fatality
case and the combination of I0 = 3300 and the fatality rate ν = 0.001 as the low
fatality case.
I consider two computational experiments in the next two sections. In the first,
I compute the implications of the model for deaths and active infections under the
high and low fatality cases with the normalized transmission rate Rt held constant
at 2.5. I then consider the implications of the model under the high and low fatality
cases under the assumption that the normalized transmission rate Rt drops rapidly
from 2.5 to 1.25, corresponding to a 50% reduction in transmission due to mitigation.

4

Model Experiment 1: Constant Rt

Let us now look at the model implications for the evolution of I, R, and deaths D
under the assumption that I0 = 330 and the fatality rate ν = 0.01 (1%) and the
alternative assumption that I0 = 3300 and the fatality rate ν = 0.001 (1/10 of 1%)
when we set Rt = 2.5 for all t.
In Figure 1, I show the path for the cumulative number of deaths in the high and
7

low fatality cases with Rt constant at 2.5. We see clearly in this figure that these two
alternative parameter configurations have dramatically different implications for the
long-run number of deaths — something close to 3 million in one case and 300,000
in the other.
In Figure 2, I zoom in on the implications of the model for the first 180 days. I plot
the log of the cumulative number of deaths in the high and low fatality cases with
Rt constant at 2.5. I omit data from the first 20 days as the initial number of deaths
is so low that taking logs is problematic. We see in this figure that the implications
of the model for deaths in the high and low fatality cases are virtually impossible to
distinguish in the first 45-50 days. After 60 days, the non-linearities in the model
begin to kick in to allow the two cases to be distinguished. (Note that in this initial
phases of the epidemic between days 20 and 40, the doubling time of deaths with
these parameters is on the order of 3.3 days regardless of the death rate).

8

10 6

3

2.5

2

1.5

1

0.5

0
0

100

200

300

400

500

days

Figure 1: Cumulative Deaths over 18 months with ν = 1% and ν = 0.1%

9

600

16

14

12

10

8

6

4
0

20

40

60

80

100

120

140

160

180

days

Figure 2: Log of Cumulative Deaths over 120 days with ν = 1% and ν = 0.1%

How is it that the model gives such similar implications for deaths in the early phase
of the epidemic under these dramatically different assumptions about the fatality rate
of the disease? The answer has to do with the differences in the model’s implications
for the number of active cases I and resistant population R.
In figure 3, I show the cumulative number of cases and the number of actively
infected under the high and low fatality scenario. Because, under the high fatality
scenario, the initial condition for I0 is higher, cumulative cases and active infections
in that case lead those in the low fatality scenario. Around day 45 of the epidemic,

10

the differences in the model implications for R + I and I under these two alternative
parameter configurations is enormous. After day 100, this difference has completely
disappeared. As a result, the fatality rate ν becomes obvious after that date simply
because the deaths do not materialize in the low fatality case.
In Figure 4, I show the logarithm of active infections I and cumulative cases R + I
under the two parameter configurations considered. We see in this figure that the
ratio of I to I + R behaves very similarly across the two parameter configurations
during the period from 20 to 45 days. We see clearly that the series across the two
parameter configurations are simply proportional shifts of each other. Thus, data
on active infections and cumulative cases would not be helpful in distinguishing the
two cases if we do not have information about the proportional measurement error
of active infections ηI .
To gain rough intuition for the results here, consider the evolution of the model
under the simplifying assumption of no congestion in the transmission of the disease.
That is, consider an approximation to our model in the early phase of the epidemic
in which S/N is close to one. Then we have
dI/dt ≈ (Rt − 1) γI
dR/dt = γI
As these equations make clear, the level of R at any date in the initial phase of the
epidemic simply scales in the initial condition I0 and thus the model implications for
the fatality rate
ν̃ = D/R
varies inversely with the initial condition I0 . It becomes possible to distinguish the
high and low fatality cases only when the non-linearities induced by the congestion
term S/N kick in.

11

10 8

3

2.5

2

1.5

1

0.5

0
0

20

40

60

80

100

120

140

160

180

days

Figure 3: Cumulative cases and active infections under the high and low fatality cases

12

20

18

16

14

12

10

8

6
0

20

40

60

80

100

120

140

160

180

days

Figure 4: The log of cumulative cases and active infections under the high and low fatality cases

5

Model Experiment 2: Falling Rt

Let us now look at the model implications for the evolution of I, R, and deaths D
under the assumption that I0 = 330 and the fatality rate ν = 0.01 (1%) and the
alternative assumption that I0 = 3300 and the fatality rate ν = 0.001 (1/10 of 1%)
when we set Rt = 2.5 to start and then have it fall rapidly to Rt = 1.25 due to
long-lasting mitigation measures. Again, we refer to the parameter combination of
I0 = 330 and ν = 0.01 as the high fatality case and the combination of I0 = 3300
13

and the fatality rate ν = 0.001 as the low fatality case.
In Figure 5, I show the path for the cumulative number of deaths in the high
and low fatality cases with Rt starting at 2.5 and then falling permanently to 1.25
due to long-term mitigation measures. We see clearly in this figure that mitigation
lowers the cumulative deaths under these two alternative parameter configurations,
but these two configurations still have dramatically different implications for the
long-run number of deaths — something close to 1.2 million in one case and 120,000
in the other.
10 5

14

12

10

8

6

4

2

0
0

100

200

300

400

500

days

Figure 5: Cumulative Deaths over 18 months with ν = 1% and ν = 0.1%

14

600

In Figure 6, I zoom in on the implications of the model for deaths in the first 180
days. I plot the log of the cumulative number of deaths in the high and low fatality
cases with Rt starting at 2.5 and then falling rapidly to 1.25 and remaining at that
level permanently. I omit data from the first 20 days as the initial number of deaths
is so low that taking logs is problematic. We see in this figure that the implications
of the model for deaths in the high and low fatality scenarios are virtually impossible
to distinguish in the first 120 days. Clearly, aggressive mitigation makes the problem
of estimating the fatality rate of the disease more severe.
The rough intuition for this result is that with a lower transmission rate, it takes
longer for the model non-linearities due to congestion in transmission (S/N ) to kick
in.

15

11

10

9

8

7

6

5

4

3
0

20

40

60

80

100

120

140

160

180

days

Figure 6: Log of Cumulative Deaths over 120 days with ν = 1% and ν = 0.1%

6

Conclusion:

This note serves only as an illustration of the difficulties of measuring the fatality rate
COVID-19 (or any other disease) in the early phases of the epidemic absent accurate
measurement of either resolved cases R or active infections I. The obvious policy
conclusion, made by many others, is that widespread testing is needed to understand
this disease. Absent that testing, we may simply have to wait to see whether lots
of people die to get an accurate estimate of the danger of this disease. Let us hope
16

that the data from the German testing program becomes available soon.

17

References
Bettencourt LM. Chowell G, Nishiura H. Comparative estimation of the reproduction
number for pandemic influenza from daily case notification data. J R Soc Interface,
4(2):155–166, Feb 22 2007.
Jose Lourenco, Robert Paton, Mahan Ghafari, Moritz Kraemer, Craig Thompson,
Peter Simmonds, Paul Klenerman, and Sunetra Gupta. Fundamental principles of
epidemic spread highlight the immediate need for large-scale serological surveys to
assess the stage of the sars-cov-2 epidemic. Cold Spring Harbor Laboratory Press,
March 26 2020.
James H. Stock. Data gaps and the policy response to the novel coronavirus. March
25 2020.
Alexis Akira Toda. Susceptible-infected-recovered (sir) dynamics of covid-19 and
economic impact. Cornell University, March 25 2020.
Chaolong Wang, Li Liu, Xingjie Hao, Huan Guo, Qi Wang, Jiao Huang, Na He,
Hongjie Yu, Xihong Lin, An Pan, Sheng Wei, and Tangchun Wu. Evolving epidemiology and impact of non-pharmaceutical interventions on the outbreak of coronavirus
disease 2019 in wuhan, china. Cold Spring Harbor Laboratory Press, March 6 2020.

18

